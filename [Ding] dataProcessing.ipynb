{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3e2f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library \n",
    "import wfdb\n",
    "import pywt\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.python.keras import Model, Input\n",
    "from tensorflow.python.keras.layers import LSTM, Dropout, Dense,Attention, multiply\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.core import *\n",
    "from wfdb import processing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c034286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "custom function\n",
    "\"\"\"\n",
    "# Use the GQRS detection algorithm and correct the peaks\n",
    "def peaks_hr(sig, peak_inds, fs, title, figsize=(20, 10), saveto=None):\n",
    "    \"Plot a signal with its peaks and heart rate\"\n",
    "    # Calculate heart rate\n",
    "    hrs = processing.hr.compute_hr(sig_len=sig.shape[0], qrs_inds=peak_inds, fs=fs)\n",
    "    \n",
    "    N = sig.shape[0]\n",
    "    \n",
    "    fig, ax_left = plt.subplots(figsize=figsize)\n",
    "    ax_right = ax_left.twinx()\n",
    "    \n",
    "    ax_left.plot(sig, color='#3979f0', label='Signal')\n",
    "    ax_left.plot(peak_inds, sig[peak_inds], 'rx', marker='x', \n",
    "                 color='#8b0000', label='Peak', markersize=12)\n",
    "    ax_right.plot(np.arange(N), hrs, label='Heart rate', color='m', linewidth=2)\n",
    "\n",
    "    ax_left.set_title(title)\n",
    "\n",
    "    ax_left.set_xlabel('Time (ms)')\n",
    "    ax_left.set_ylabel('ECG (mV)', color='#3979f0')\n",
    "    ax_right.set_ylabel('Heart rate (bpm)', color='m')\n",
    "    # Make the y-axis label, ticks and tick labels match the line color.\n",
    "    ax_left.tick_params('y', colors='#3979f0')\n",
    "    ax_right.tick_params('y', colors='m')\n",
    "    if saveto is not None:\n",
    "        plt.savefig(saveto, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# compute_hr: This is the compute the heart rate\n",
    "# sig_len: \n",
    "# qrs_ins: \n",
    "# fs: frequency\n",
    "def compute_hr(sig_len, qrs_ins, fs):\n",
    "    heart_rate = np.full(sig_len, np.nan, dtype = \"float32\")\n",
    "\n",
    "    if len(qrs_inds) < 2:\n",
    "        return heart_rate\n",
    "\n",
    "    for i in range(0, len(qrs_inds) - 2):\n",
    "            a = qrs_inds[i]\n",
    "            b = qrs_inds[i + 1]\n",
    "            c = qrs_inds[i + 2]\n",
    "            rr = (b - a) * (1.0 / fs) * 1000\n",
    "            hr = 60000.0 / rr\n",
    "            heart_rate[b + 1: c + 1] = hr\n",
    "\n",
    "            heart_rate[qrs_inds[-1]:] = heart_rate[qrs_inds[-1]]\n",
    "\n",
    "            return heart_rate\n",
    "        \n",
    "# compute_hr_custom: This is the compute the custom hr \n",
    "# sig_len: \n",
    "# qrs_ins: \n",
    "# fs: frequency\n",
    "\n",
    "def compute_respiratory(r_peak_1, r_peak_2, fs):\n",
    "     a = r_peak_1\n",
    "     b = r_peak_2\n",
    "     rr = (b - a) * (1.0 / fs)\n",
    "     hr = 60 / rr\n",
    "\n",
    "     return hr\n",
    "    \n",
    "# dont know wtf for this\n",
    "def denoise(data):\n",
    "   \n",
    "    coeffs = pywt.wavedec(data=data, wavelet='db5', level = 9)\n",
    "    cA9, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1 = coeffs\n",
    "\n",
    "    threshold = (np.median(np.abs(cD1)) / 0.6745) * (np.sqrt(2 * np.log(len(cD1))))\n",
    "    cD1.fill(0)\n",
    "    cD2.fill(0)\n",
    "    \n",
    "    for i in range(1, len(coeffs) - 2):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold)\n",
    "\n",
    "    rdata = pywt.waverec(coeffs=coeffs, wavelet='db5')\n",
    "    return rdata\n",
    "\n",
    "\n",
    "def plotHeatMap(Y_test, Y_pred):\n",
    "    con_mat = confusion_matrix(Y_test, Y_pred)\n",
    "    # 绘图\n",
    "    plt.figure(figsize=(4, 5))\n",
    "    seaborn.heatmap(con_mat, annot=True, fmt='.20g', cmap='Blues')\n",
    "    plt.ylim(0, 5)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def buildModel():\n",
    "    newModel = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(300, 1)),\n",
    "        # 第一个卷积层, 4 个 21x1 卷积核\n",
    "        tf.keras.layers.Conv1D(filters=4, kernel_size=21, strides=1, padding='SAME', activation='tanh'),\n",
    "        # 第一个池化层, 最大池化,4 个 3x1 卷积核, 步长为 2\n",
    "        tf.keras.layers.MaxPool1D(pool_size=3, strides=2, padding='SAME'),\n",
    "        # 第二个卷积层, 16 个 23x1 卷积核\n",
    "        tf.keras.layers.Conv1D(filters=16, kernel_size=23, strides=1, padding='SAME', activation='relu'),\n",
    "        # 第二个池化层, 最大池化,4 个 3x1 卷积核, 步长为 2\n",
    "        tf.keras.layers.MaxPool1D(pool_size=3, strides=2, padding='SAME'),\n",
    "        # 第三个卷积层, 32 个 25x1 卷积核\n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=25, strides=1, padding='SAME', activation='tanh'),\n",
    "        # 第三个池化层, 平均池化,4 个 3x1 卷积核, 步长为 2\n",
    "        tf.keras.layers.AvgPool1D(pool_size=3, strides=2, padding='SAME'),\n",
    "        # 第四个卷积层, 64 个 27x1 卷积核\n",
    "        tf.keras.layers.Conv1D(filters=64, kernel_size=27, strides=1, padding='SAME', activation='relu'),\n",
    "        # 打平层,方便全连接层处理'\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # 全连接层,128 个节点 转换成128个节点\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        # Dropout层,dropout = 0.2\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        # 全连接层,5 个节点\n",
    "        tf.keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "    return newModel\n",
    "\n",
    "def plotHeatMap(Y_test, Y_pred):\n",
    "    con_mat = confusion_matrix(Y_test, Y_pred)\n",
    "    # 绘图\n",
    "    plt.figure(figsize=(4, 5))\n",
    "    seaborn.heatmap(con_mat, annot=True, fmt='.20g', cmap='Blues')\n",
    "    plt.ylim(0, 5)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f56c16a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '，' (U+FF0C) (414439895.py, line 132)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[51], line 132\u001B[0;36m\u001B[0m\n\u001B[0;31m    df3 = pd.merge(resp_df, final_resp_df, how='inner'，left_on='Time(sec)', right_on='Time(sec)')\u001B[0m\n\u001B[0m                                                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid character '，' (U+FF0C)\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "\"\"\"\n",
    "Step 1: Load sample data for 1..10 infants\n",
    "\n",
    "heart_data: list of heart rate ECG sample data\n",
    "resp_data: list of respiratory data\n",
    "\n",
    "\"\"\"\n",
    "# Constant files\n",
    "ecg_file = './DataSet/files/picsdb/1.0.0/infant{}_ecg'\n",
    "resp_file = './DataSet/files/picsdb/1.0.0/infant{}_resp'\n",
    "numbers_infants = 3\n",
    "sampfrom = 0\n",
    "sampto = 1000\n",
    "\n",
    "for i in range(1, numbers_infants):\n",
    "    print(\"Loading infants\", i, \"...\")\n",
    "\n",
    "    ecg_record = wfdb.rdrecord(ecg_file.format(i), sampfrom = sampfrom, sampto = sampto)\n",
    "    ecg_annotation = wfdb.rdann(ecg_file.format(i), 'qrsc', sampfrom = sampfrom, sampto = sampto)\n",
    "\n",
    "    resp_record = wfdb.rdrecord(resp_file.format(i), sampfrom = sampfrom, sampto = sampto)\n",
    "    resp_annotation = wfdb.rdann(resp_file.format(i), 'resp', sampfrom = sampfrom, sampto = sampto)\n",
    "\n",
    "#     wfdb.plot_wfdb(record=ecg_record, annotation=ecg_annotation,\n",
    "#                title='Record from ECG',\n",
    "#                time_units='minutes')\n",
    "    \n",
    "#     wfdb.plot_wfdb(record=resp_record, annotation=resp_annotation,\n",
    "#                title='Record from respiratory',\n",
    "#                time_units='minutes')\n",
    "        \n",
    "\n",
    "    \"\"\"DEBUG\"\"\"\n",
    "    # Display record dictionary\n",
    "    #     display(ecg_record.__dict__)\n",
    "#     display(resp_record.__dict__)\n",
    "\n",
    "    \n",
    "    # Convert to p_signal\n",
    "    ecg_p_signal = ecg_record.p_signal\n",
    "    resp_p_signal = resp_record.p_signal\n",
    "\n",
    "    # ECG Signal Grpah\n",
    "    plt.plot(ecg_p_signal)\n",
    "    plt.title(\"ECG Signal\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Respiratory Signal Grpah\n",
    "    plt.plot(resp_p_signal)\n",
    "    plt.title(\"Respiratory Signal\")\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\" \n",
    "    STEP 1\n",
    "    REFINING THE GRAPH - ECG\n",
    "    \"\"\"\n",
    "    # Use the GQRS algorithm to detect QRS locations in the first channel\n",
    "    qrs_inds = processing.qrs.gqrs_detect(sig = ecg_record.p_signal, fs = ecg_record.fs)\n",
    "    \n",
    "    # Correct the peaks shifting them to local maxima\n",
    "    min_bpm = 20\n",
    "    max_bpm = 230\n",
    "    min_gap = ecg_record.fs * 60 / min_bpm\n",
    "\n",
    "    denoise_record_p_signal = denoise(ecg_record.p_signal.flatten())\n",
    "    denoise_record_fs = ecg_record.fs \n",
    "    # denoise_record_fs = denoise(ecg_record.fs) \n",
    "\n",
    "    # Use the maximum possible bpm as the search radius\n",
    "    peaks_hr(sig = ecg_record.p_signal, peak_inds=qrs_inds, fs=ecg_record.fs,\n",
    "         title=\"GQRS peak detection on record 100\")\n",
    "    \n",
    "    search_radius = int(denoise_record_fs * 60 / max_bpm)\n",
    "    corrected_peak_inds = processing.peaks.correct_peaks(denoise_record_p_signal, \n",
    "                                                         peak_inds=qrs_inds,\n",
    "                                                         search_radius=search_radius, \n",
    "                                                         smooth_window_size=150)\n",
    "\n",
    "    print('Corrected GQRS detected peak indices:', sorted(corrected_peak_inds))\n",
    "    peaks_hr(sig = ecg_record.p_signal, peak_inds = sorted(corrected_peak_inds), fs=ecg_record.fs,\n",
    "         title=\"Corrected GQRS peak detection on sampledata/\" + str(sampto))\n",
    "\n",
    "    \n",
    "    \"\"\" \n",
    "    STEP 2\n",
    "    Calculating the heart rate\n",
    "    Corelation: \n",
    "    heart_rate = by checking\n",
    "    \"\"\"\n",
    "    \n",
    "    # Heart rate and respiratory rate\n",
    "    heart_rate = processing.compute_hr(len(ecg_record.p_signal), sorted(corrected_peak_inds), ecg_record.fs)\n",
    "    breathing_rate = resp_record.p_signal.flatten()\n",
    "    \n",
    "    ecg_samp_interval = 1 / ecg_record.fs\n",
    "    resp_samp_interval = 1 / resp_record.fs\n",
    "\n",
    "    print(\"ECG slp frequecy:\", ecg_record.fs, \"Hz\")\n",
    "    print(\"ECG slp interval every:\", ecg_samp_interval, \"sec\")\n",
    "\n",
    "    print(\"RESP slp frequecy:\" , resp_record.fs, \"Hz\")\n",
    "    print(\"RESP slp interval every:\", ecg_samp_interval, \"sec\")\n",
    "    print(\"\")\n",
    "    \n",
    "    time_ecg = np.arange(ecg_record.p_signal.shape[0]) * ecg_samp_interval\n",
    "    time_resp = np.arange(resp_record.p_signal.shape[0]) * resp_samp_interval\n",
    "    \n",
    "    heart_data = {\n",
    "        'Infant:': i,\n",
    "        'Heart_rate': heart_rate,\n",
    "        'Time(sec)': time_ecg,\n",
    "    }\n",
    "\n",
    "    resp_data = {\n",
    "        'Infant:': i,\n",
    "        'Heart_rate': breathing_rate,\n",
    "        'Time(sec)': time_resp, \n",
    "    }\n",
    "\n",
    "    \n",
    "    # dropna() -> Remove NaN\n",
    "    heart_df = pd.DataFrame.from_dict(heart_data).dropna()\n",
    "    \n",
    "    columns = [column for column in heart_df.columns if resp_df[column].nunique()==1]\n",
    "    resp_df.drop(columns=columns)\n",
    "\n",
    "    final_resp_df = pd.DataFrame.from_dict(resp_data)\n",
    "    \n",
    "\n",
    "    a = np.intersect1d(heart_df.columns, final_resp_df.columns)\n",
    "    \n",
    "    df3 = pd.merge(resp_df, final_resp_df, how='inner'，left_on='Time(sec)', right_on='Time(sec)')\n",
    "\n",
    "    print(\"heart_df\", heart_df)\n",
    "    print(\"resp_df\", resp_df, final_resp_df)\n",
    "    print(\"df3\", df3)\n",
    "\n",
    "    \"\"\"\n",
    "    Train data set\n",
    "    \"\"\"\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(heart_df, resp_df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Data Modelling 1: SVM\n",
    "    \"\"\"\n",
    "    # show unclassified data\n",
    "#     plt.scatter(X_train, Y_train)\n",
    "#     plt.show()\n",
    "\n",
    "#     print(\"X_train\", len(X_train))\n",
    "#     print(\"X_test\", len(X_test))\n",
    "#     print(\"y_train\", len(Y_train))\n",
    "#     print(\"y_test\", len(Y_test))\n",
    "    \n",
    "#     clf = svm.SVC(kernel='linear', C=1.0)\n",
    "#     clf.fit(X_train, Y_train)\n",
    "    \n",
    "#     print(\"\")\n",
    "\n",
    "\n",
    "print(\"Trained All infants data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b066c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b2ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "\n",
    " \n",
    "tf.keras.models.fit(X_train, Y_train, validation_split = \"linear\")  # validation_split 训练集所占比例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd6391e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
